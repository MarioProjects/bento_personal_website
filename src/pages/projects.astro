---
import Layout from "../layouts/Layout.astro";
import Project from "../components/Project.astro";
import { Icon } from "astro-icon/components";
---

<script>
  import { stagger, spring, timeline, type TimelineDefinition } from "motion";
  import { loaderAnimation } from "../lib/constants";
  const cards = document.querySelectorAll(".card");

  const sequence = [
    loaderAnimation,
    [
      cards,
      { y: ["40%", "0%"], opacity: [0, 1] },
      {
        at: "-0.1",
        duration: 0.4,
        delay: stagger(0.3),
        easing: spring({ velocity: 100, stiffness: 50, damping: 10 }),
      },
    ],
  ];

  timeline(sequence as TimelineDefinition);
</script>

<Layout
  title="Mario ParreÃ±o - Projects"
  description="I'm a Machine Learning engineer specializing in Computer Vision and Generative AI, automating problems that save companies time and money. Currently, I'm focused on tackling real-world problems with Deep Learning."
>
  <main
    class="z-10 w-screen h-full flex flex-col justify-start items-start max-w-3xl mx-auto p-8"
  >
    <a
      href="/"
      class="w-auto flex text-white bg-neutral-900 hover:bg-neutral-800 px-4 py-2 mb-8 border-1 border-solid border-neutral-600 rounded-lg"
      >
      <Icon size={22} name="mdi:arrow-back" class="h-6 mr-1" />
      Back To Home
      </a
    >
    <h1 class="text-4xl font-bold mb-4">Personal Projects</h1>
    <div class="flex flex-col gap-4 w-full space-y-2 pb-12">
      <Project
        title="FLoRA"
        description=" The aim of this project is to provide a simple and easy-to-use implementation of LoRA for fine-tuning LLMs. To test the implementation, we tackle the MNLI subtask of the GLUE benchmark."
        url="https://github.com/AIdventures/flora"
      />
      <Project
        title="microViT"
        description="microViT is a streamlined implementation of the Vision Transformer (ViT) architecture, focusing solely on the encoder component. This project applies the microViT model to the classic task of handwritten digit classification using the MNIST dataset."
        url="https://github.com/AIdventures/microViT"
      />
      <Project
        title="microTransformer"
        description="microTransformer is based on the raw implementation of the Transformer model, with the encoder and decoder parts. The task we will be working on is the sorting of a sequence of characters. For example, the sequence 'ABCB' will be sorted as 'ABBC'."
        url="https://github.com/AIdventures/microTransformer"
      />
      <Project
        title="DASeGAN"
        description="Framework inspired in CycleGAN for domain adaptation and generalization using GANs to map images into a universal domain for segmentation tasks, unifying appearance across domains through adversarial training."
        url="DASeGAN.pdf"
      />
      <Project
        title="Dobble"
        description="Through web scrapping techniques, it is possible to collect images of the works in the Prado museum. We have hundreds of algorithms to detect faces. We can obtain embeddings that encode our faces using Siamese neural networks. We just need to get the closest embedding!"
        url="https://dobble.maparla.es"
      />
      <Project
        title="Agro Analysis"
        description="Analysis of the behavior of the Spanish fruit and vegetable market during the pandemic period with data from different sources. National competition obtaining the third place."
        url="https://agro.maparla.es"
      />
    </div>
  </main>
</Layout>
